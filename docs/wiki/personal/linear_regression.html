


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<head>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="stylesheet" href="/wiki.css">

<title>linear regression</title>

</head>

<div class="site-title"><a href="./">Personal Wiki</a> by <a href="https://philipkd.com/">Philip Dhingra</a></div>

<div class="entry">

<div class="page-title">linear regression</div>

<p><strong>Wx+b = Y.</strong></p>

<p>W is adjusted in steps based on a step function using Gradient Descent.</p>

<p>Has 91% accuracy on MNIST</p>

<h1>Canonical Example: Gradient Descent</h1>

<p>The goal of supervised learning is to find the weights that minimize a cost function. However, the cost graph is unknown and we can't figure out the global minimum, so we have to walk in steps. Calculate the derivative at any point. A 1 means a 45 degree angle, a 10 means a very steep one, and then you multiply by the -1 and the learning rate, which should be a tiny step, like 0.0001, depending on how bumpy the cost graph is.</p>

<p><em>A <strong>vanishing</strong> or <strong>sparse gradient</strong> happens when the slope is too shallow, like 0.0001, such that moving small steps in that direction, doesn't help.</em></p>

<p><img src="gradient-descent.png" alt="" /></p>

<h2>Adam Optimizer</h2>

<p>Optimizers do special things to gradients when calculating weight updates. Adam optimizer calculates the slope using a exponentially decaying average of the slopes at each training step. It uses β1 and β2 to represent the decay rates for the first (mean) and second (std. dev) moments of the cost function. Higher betas mean "include more of" the history when calculating the moments. Lower beta means tinier steps.</p>

<p>Given that the weight updates = -1 * gradient * learning&#95;rate, then smaller betas should lead to slower training.</p>

<h2>Progression</h2>

<ol>
<li><p>Training:</p>

<p>a. Sample: one example that could be inputted into <strong>Wx+b = Y</strong><br />
b. Batch (also called a step): a set of samples that leads to one update to <strong>W</strong>  (batch size of 32 is a <a href="https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network">good start</a>, but should also try 64, 128, and 256)<br />
c. Step: Calculate the partial derivative of each data point given the <strong>W</strong>, then move the weights the step increment in the direction that reduces cost<br />
d. Epoch: when every sample in the training dataset has been run through once (usually run for 10, 100, 500, 1000, and <a href="https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/">larger</a>)</p></li>
<li><p>Validation:</p>

<p>a. Know how many epochs to stop training<br />
b. Find better hyperparams<br />
c. You don't use the validation loss to change the weights</p></li>
<li><p>Test:</p>

<p>a. Measure performance of best model against this set<br />
b. No automated model creation after this  </p></li>
</ol>

<h2>"Cost"</h2>

<p>Using MNIST as example:</p>

<ul>
<li>sample is (pixels,ground-truth label) for each image</li>
<li>y-estimate = Mx + b, where x is pixels</li>
<li>y-actual = label</li>
<li>cost = y-estimate - y-actual</li>
</ul>

<h2>Mini-Batch</h2>

<ul>
<li>Batch Gradient Descent. Batch Size = Size of Training Set</li>
<li>Stochastic Gradient Descent. Batch Size = 1</li>
<li>Mini-Batch Gradient Descent. 1 &lt; Batch Size &lt; Size of Training Set</li>
</ul>

<h1>Backpropagation</h1>

<p>Backpropagation is just a way to calculate the first derivative of a cost function.</p>

<blockquote>
  <p>The goal of backpropagation is to compute the partial derivatives ∂C/∂w and ∂C/∂b of the cost function C with respect to any weight w or bias b in the network"</p>
</blockquote>

<p><a href="https://towardsdatascience.com/part-2-gradient-descent-and-backpropagation-bf90932c066a">source</a></p>

<p>It's called backpropogatation, because in a multi-layer feedforward network, the weights roll back from the last layer to the first layer.</p>

<blockquote>
  <p>Sometimes a multilayer feedforward neural network is referred to incorrectly as a back-propagation network. The term back-propagation does not refer to the structure or architecture of a network. Back-propagation is a method for calculating the first derivative, or gradient, of the error function required by some optimization methods.</p>
</blockquote>

<p><a href="https://docs.roguewave.com/en/imsl/c/2016.1/html/cnlstat/index.html#page/CNL%20Stat/csch13.16.42.html">source</a></p>

<br/>
<a href="https://licensebuttons.net/l/by/4.0/"><img src="https://licensebuttons.net/l/by/4.0/80x15.png"></a>